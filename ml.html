<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Quiz de Machine Learning</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.3.0/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css" rel="stylesheet">
    <style>
        body {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        .quiz-container {
            max-width: 900px;
            margin: 0 auto;
        }
        .card {
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
        }
        .option-btn {
            text-align: left;
            margin: 10px 0;
            padding: 15px;
            border: 2px solid #e0e0e0;
            transition: all 0.3s;
        }
        .option-btn:hover {
            transform: translateX(5px);
            border-color: #667eea;
        }
        .option-btn.correct {
            background-color: #d4edda;
            border-color: #28a745;
        }
        .option-btn.incorrect {
            background-color: #f8d7da;
            border-color: #dc3545;
        }
        .progress {
            height: 25px;
            border-radius: 10px;
        }
        .explanation-box {
            background-color: #f8f9fa;
            border-left: 4px solid #667eea;
            padding: 15px;
            margin-top: 15px;
            border-radius: 5px;
        }
        .score-badge {
            font-size: 3rem;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="quiz-container">
        <div id="startScreen" class="card p-4 animate__animated animate__fadeIn">
            <div class="text-center">
                <i class="fas fa-brain fa-5x text-primary mb-4"></i>
                <h1 class="mb-3">Quiz de Machine Learning</h1>
                <p class="lead mb-4">Pon a prueba tus conocimientos sobre fundamentos de ML, algoritmos, métricas y más.</p>
                <p class="text-muted mb-4">
                    <i class="fas fa-info-circle"></i> <span id="totalQuestions"></span> preguntas completas del banco
                </p>
                <button class="btn btn-primary btn-lg" onclick="startQuiz()">
                    <i class="fas fa-play"></i> Comenzar Quiz
                </button>
            </div>
        </div>

        <div id="quizScreen" class="card p-4 animate__animated animate__fadeIn" style="display: none;">
            <div class="mb-4">
                <div class="d-flex justify-content-between align-items-center mb-2">
                    <h5>Pregunta <span id="currentQuestion">1</span> de <span id="totalQuestionsQuiz"></span></h5>
                    <span class="badge bg-primary">Puntos: <span id="score">0</span></span>
                </div>
                <div class="progress">
                    <div id="progressBar" class="progress-bar bg-success" role="progressbar" style="width: 5%"></div>
                </div>
            </div>

            <div id="questionCard">
                <h4 class="mb-4" id="questionText"></h4>
                <div id="optionsContainer"></div>
                <div id="explanationContainer" style="display: none;"></div>
            </div>

            <div class="text-center mt-4">
                <button id="nextBtn" class="btn btn-primary" onclick="nextQuestion()" style="display: none;">
                    Siguiente Pregunta <i class="fas fa-arrow-right"></i>
                </button>
            </div>
        </div>

        <div id="resultScreen" class="card p-4 animate__animated animate__fadeIn" style="display: none;">
            <div class="text-center">
                <i class="fas fa-trophy fa-5x text-warning mb-4"></i>
                <h2 class="mb-4">¡Quiz Completado!</h2>
                <div class="score-badge mb-4" id="finalScore"></div>
                <div id="performance" class="mb-4"></div>
                <button class="btn btn-primary btn-lg" onclick="location.reload()">
                    <i class="fas fa-redo"></i> Intentar de Nuevo
                </button>
            </div>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.3.0/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/sweetalert/2.1.2/sweetalert.min.js"></script>
    <script>
        // Mostrar total de preguntas al cargar
        window.addEventListener('DOMContentLoaded', function() {
            // Se actualizará después de definir questionBank
        });

        // Banco extenso de preguntas
        const questionBank = [
            {
                question: "En una matriz de confusión, ¿qué representa un Verdadero Positivo (TP)?",
                options: [
                    "Casos positivos predichos correctamente como positivos",
                    "Casos negativos predichos incorrectamente como positivos",
                    "Casos positivos predichos incorrectamente como negativos",
                    "Casos negativos predichos correctamente como negativos"
                ],
                correct: 0,
                explanation: "Un Verdadero Positivo (TP) ocurre cuando el modelo predice la clase positiva y la instancia realmente pertenece a la clase positiva. Es un acierto en la predicción de casos positivos."
            },
            {
                question: "¿Qué métrica es más apropiada cuando las clases están desbalanceadas?",
                options: [
                    "Accuracy (Exactitud)",
                    "F1-Score",
                    "Tiempo de entrenamiento",
                    "Número de características"
                ],
                correct: 1,
                explanation: "El F1-Score es la media armónica entre Precision y Recall, lo que lo hace ideal para datos desbalanceados. El Accuracy puede ser engañoso cuando una clase domina el dataset, ya que un modelo que siempre predice la clase mayoritaria tendría alta exactitud pero sería inútil."
            },
            {
                question: "¿Qué es un Falso Positivo (FP)?",
                options: [
                    "Predecir positivo cuando es negativo",
                    "Predecir negativo cuando es positivo",
                    "Predecir positivo cuando es positivo",
                    "Predecir negativo cuando es negativo"
                ],
                correct: 0,
                explanation: "Un Falso Positivo (FP) es un error tipo I, donde el modelo predice que algo es positivo cuando en realidad es negativo. Por ejemplo, diagnosticar una enfermedad a una persona sana."
            },
            {
                question: "La fórmula de Precision es:",
                options: [
                    "TP / (TP + FP)",
                    "TP / (TP + FN)",
                    "TP / (TN + FP)",
                    "(TP + TN) / Total"
                ],
                correct: 0,
                explanation: "Precision = TP / (TP + FP). Mide de todos los casos que predijimos como positivos, cuántos realmente lo son. Es crucial cuando los falsos positivos son costosos (ej: emails marcados como spam)."
            },
            {
                question: "La fórmula de Recall (Sensibilidad) es:",
                options: [
                    "TP / (TP + FP)",
                    "TP / (TP + FN)",
                    "TN / (TN + FP)",
                    "(TP + TN) / Total"
                ],
                correct: 1,
                explanation: "Recall = TP / (TP + FN). Mide de todos los casos que realmente son positivos, cuántos detectamos. Es crítico cuando los falsos negativos son costosos (ej: no detectar un cáncer)."
            },
            {
                question: "¿Qué representa la Especificidad?",
                options: [
                    "Proporción de negativos correctamente identificados",
                    "Proporción de positivos correctamente identificados",
                    "Promedio de precision y recall",
                    "Tasa de error del modelo"
                ],
                correct: 0,
                explanation: "Especificidad = TN / (TN + FP). Mide la capacidad del modelo para identificar correctamente los casos negativos. Es complementaria al Recall, que se enfoca en los positivos."
            },
            {
                question: "En DBSCAN, ¿qué es un punto núcleo (core point)?",
                options: [
                    "Un punto con al menos MinPts vecinos dentro de epsilon",
                    "Un punto en el borde de un cluster",
                    "Un punto aislado considerado ruido",
                    "El centroide del cluster"
                ],
                correct: 0,
                explanation: "Un punto núcleo en DBSCAN tiene al menos MinPts puntos (incluyéndose a sí mismo) dentro de su vecindad epsilon. Estos puntos forman la base de los clusters y pueden expandir el cluster a sus vecinos."
            },
            {
                question: "DBSCAN requiere especificar de antemano el número de clusters:",
                options: [
                    "Verdadero",
                    "Falso"
                ],
                correct: 1,
                explanation: "FALSO. A diferencia de K-Means, DBSCAN descubre automáticamente el número de clusters basándose en la densidad de los datos. Solo necesitas especificar epsilon (radio) y MinPts (mínimo de puntos)."
            },
            {
                question: "¿Cuál es la principal ventaja de DBSCAN sobre K-Means?",
                options: [
                    "Puede encontrar clusters de formas arbitrarias",
                    "Es más rápido",
                    "Requiere menos parámetros",
                    "Siempre converge a la solución óptima"
                ],
                correct: 0,
                explanation: "DBSCAN puede detectar clusters de formas arbitrarias y no asume que los clusters son esféricos como K-Means. Además, puede identificar outliers como ruido, lo que K-Means no hace."
            },
            {
                question: "En un Decision Tree, ¿qué mide la Ganancia de Información?",
                options: [
                    "La reducción de entropía al hacer una división",
                    "El error de clasificación",
                    "La profundidad del árbol",
                    "El número de hojas"
                ],
                correct: 0,
                explanation: "La Ganancia de Información mide cuánto reduce la entropía (incertidumbre) una división específica. Se calcula como: Entropía(padre) - Promedio ponderado de Entropía(hijos). Mayor ganancia = mejor división."
            },
            {
                question: "¿Qué es el overfitting en un Decision Tree?",
                options: [
                    "Cuando el árbol memoriza los datos de entrenamiento",
                    "Cuando el árbol es muy simple",
                    "Cuando hay pocas características",
                    "Cuando se usa poda"
                ],
                correct: 0,
                explanation: "Overfitting ocurre cuando el árbol se vuelve demasiado complejo y aprende el ruido en los datos de entrenamiento, resultando en mal desempeño en datos nuevos. Se previene con poda, limitando la profundidad o el número mínimo de muestras por hoja."
            },
            {
                question: "Random Forest funciona mediante:",
                options: [
                    "Combinación de múltiples árboles de decisión",
                    "Un solo árbol muy profundo",
                    "Clustering jerárquico",
                    "Regresión lineal múltiple"
                ],
                correct: 0,
                explanation: "Random Forest es un método de ensemble que entrena múltiples árboles de decisión en subconjuntos aleatorios de datos y características (bagging + feature sampling), y combina sus predicciones mediante votación (clasificación) o promedio (regresión)."
            },
            {
                question: "¿Qué técnica usa Random Forest para reducir la correlación entre árboles?",
                options: [
                    "Usar solo un subconjunto aleatorio de características en cada división",
                    "Podar todos los árboles igualmente",
                    "Usar el mismo dataset para todos los árboles",
                    "Entrenar árboles secuencialmente"
                ],
                correct: 0,
                explanation: "Random Forest usa 'random feature selection' en cada división, considerando solo un subconjunto aleatorio de características (típicamente sqrt(n_features)). Esto reduce la correlación entre árboles, mejorando la diversidad del ensemble y reduciendo el overfitting."
            },
            {
                question: "En regresión lineal, ¿qué minimizamos para encontrar los parámetros óptimos?",
                options: [
                    "La suma de errores cuadráticos (SSE/MSE)",
                    "El número de características",
                    "La entropía",
                    "El número de iteraciones"
                ],
                correct: 0,
                explanation: "En regresión lineal minimizamos la suma de errores cuadráticos (SSE) o su promedio (MSE - Mean Squared Error). Esto se conoce como método de mínimos cuadrados ordinarios (OLS), que encuentra la línea que minimiza las distancias verticales al cuadrado entre los puntos y la línea."
            },
            {
                question: "La regresión Ridge (L2) añade una penalización de:",
                options: [
                    "La suma de los cuadrados de los coeficientes",
                    "La suma de valores absolutos de los coeficientes",
                    "El número de coeficientes no-cero",
                    "La profundidad del modelo"
                ],
                correct: 0,
                explanation: "Ridge regression añade λ * Σ(βi²) a la función de costo. Esta penalización L2 reduce la magnitud de los coeficientes pero rara vez los hace exactamente cero, ayudando a prevenir overfitting cuando hay multicolinealidad."
            },
            {
                question: "La regresión Lasso (L1) puede:",
                options: [
                    "Hacer coeficientes exactamente cero (selección de características)",
                    "Solo reducir coeficientes cerca de cero",
                    "Incrementar todos los coeficientes",
                    "No afecta los coeficientes"
                ],
                correct: 0,
                explanation: "Lasso (Least Absolute Shrinkage and Selection Operator) usa penalización L1: λ * Σ|βi|. Esto puede forzar algunos coeficientes a ser exactamente cero, efectivamente realizando selección de características automática."
            },
            {
                question: "En regresión logística, la función sigmoide convierte valores a:",
                options: [
                    "Probabilidades entre 0 y 1",
                    "Valores entre -∞ y +∞",
                    "Categorías discretas",
                    "Vectores de características"
                ],
                correct: 0,
                explanation: "La función sigmoide σ(z) = 1/(1+e^(-z)) transforma cualquier valor real en un valor entre 0 y 1, interpretable como probabilidad. Para clasificación binaria, usamos un umbral (típicamente 0.5) para decidir la clase."
            },
            {
                question: "En Deep Learning, ¿qué es una neurona artificial?",
                options: [
                    "Una unidad que calcula suma ponderada + función de activación",
                    "Un algoritmo de optimización",
                    "Una técnica de regularización",
                    "Un tipo de normalización"
                ],
                correct: 0,
                explanation: "Una neurona artificial calcula: output = activación(Σ(wi*xi) + b), donde wi son pesos, xi son entradas, b es el bias, y la función de activación introduce no-linealidad (ReLU, sigmoid, tanh, etc.)."
            },
            {
                question: "¿Qué función de activación es más común en capas ocultas de redes profundas?",
                options: [
                    "ReLU (Rectified Linear Unit)",
                    "Sigmoid",
                    "Linear",
                    "Step function"
                ],
                correct: 0,
                explanation: "ReLU (f(x) = max(0,x)) es preferida porque: 1) evita el problema de gradientes desvanecientes, 2) es computacionalmente eficiente, 3) introduce no-linealidad. Sigmoid/tanh sufren de gradientes que desaparecen en redes profundas."
            },
            {
                question: "El problema del gradiente desvaneciente ocurre cuando:",
                options: [
                    "Los gradientes se vuelven muy pequeños en capas profundas",
                    "Los gradientes explotan a infinito",
                    "No hay suficientes datos",
                    "El learning rate es muy alto"
                ],
                correct: 0,
                explanation: "En redes muy profundas con activaciones como sigmoid/tanh, los gradientes se multiplican durante backpropagation y pueden volverse extremadamente pequeños, haciendo que las capas iniciales aprendan muy lentamente o no aprendan nada."
            },
            {
                question: "Dropout es una técnica que:",
                options: [
                    "Desactiva aleatoriamente neuronas durante entrenamiento",
                    "Elimina capas de la red",
                    "Reduce el learning rate",
                    "Aumenta el batch size"
                ],
                correct: 0,
                explanation: "Dropout desactiva aleatoriamente un porcentaje de neuronas en cada iteración de entrenamiento (típicamente 20-50%), forzando a la red a aprender características redundantes y más robustas, reduciendo overfitting significativamente."
            },
            {
                question: "En K-Means, ¿cómo se inicializan típicamente los centroides?",
                options: [
                    "Aleatoriamente o usando K-Means++",
                    "Siempre en el origen",
                    "En los puntos más alejados",
                    "No se inicializan"
                ],
                correct: 0,
                explanation: "K-Means es sensible a la inicialización. K-Means++ mejora la inicialización aleatoria seleccionando centroides que estén lo más lejos posible entre sí, reduciendo la probabilidad de convergencia a mínimos locales pobres."
            },
            {
                question: "¿Qué métrica usa K-Means para asignar puntos a clusters?",
                options: [
                    "Distancia euclidiana al centroide más cercano",
                    "Correlación de Pearson",
                    "Entropía",
                    "Ganancia de información"
                ],
                correct: 0,
                explanation: "K-Means asigna cada punto al centroide más cercano usando distancia euclidiana. Luego recalcula centroides como la media de los puntos asignados. Este proceso se repite hasta convergencia, minimizando la suma de distancias cuadradas intra-cluster (WCSS)."
            },
            {
                question: "El método del codo (elbow method) se usa para:",
                options: [
                    "Determinar el número óptimo de clusters en K-Means",
                    "Calcular accuracy",
                    "Normalizar datos",
                    "Dividir train/test"
                ],
                correct: 0,
                explanation: "El método del codo grafica WCSS (Within-Cluster Sum of Squares) vs número de clusters K. El punto óptimo es donde la curva hace un 'codo' - donde añadir más clusters no reduce significativamente el WCSS."
            },
            {
                question: "En SVM, ¿qué es el kernel trick?",
                options: [
                    "Transformar datos a un espacio de mayor dimensión sin calcularlo explícitamente",
                    "Reducir dimensiones del dataset",
                    "Normalizar las características",
                    "Dividir los datos en folds"
                ],
                correct: 0,
                explanation: "El kernel trick permite a SVM encontrar fronteras de decisión no-lineales mapeando implícitamente datos a un espacio de mayor dimensión usando funciones kernel (RBF, polinomial, etc.) sin calcular explícitamente las coordenadas transformadas, ahorrando computación."
            },
            {
                question: "¿Qué es el hiperparámetro C en SVM?",
                options: [
                    "Controla el trade-off entre margen amplio y errores de clasificación",
                    "El número de vectores de soporte",
                    "La dimensión del espacio transformado",
                    "El learning rate"
                ],
                correct: 0,
                explanation: "C es el parámetro de regularización: C alto = margen estrecho con pocos errores (puede overfit), C bajo = margen amplio tolerando más errores (puede underfit). Controla cuánta penalización damos a los errores de clasificación."
            },
            {
                question: "Batch Normalization se aplica:",
                options: [
                    "Después de la capa lineal, antes de la activación",
                    "Solo en la entrada de la red",
                    "Solo en la última capa",
                    "Nunca en redes profundas"
                ],
                correct: 0,
                explanation: "Batch Normalization normaliza las activaciones de cada capa usando las estadísticas del mini-batch, típicamente después de la transformación lineal y antes de la función de activación. Esto estabiliza y acelera el entrenamiento permitiendo learning rates más altos."
            },
            {
                question: "¿Qué es cross-validation?",
                options: [
                    "Técnica para evaluar modelos usando múltiples divisiones de datos",
                    "Un algoritmo de clasificación",
                    "Una función de pérdida",
                    "Un método de regularización"
                ],
                correct: 0,
                explanation: "Cross-validation (ej: k-fold CV) divide los datos en k partes, entrena k veces usando k-1 partes y valida en la parte restante, rotando. Esto da una estimación más robusta del rendimiento del modelo y reduce el riesgo de overfitting al conjunto de validación."
            },
            {
                question: "En k-fold cross-validation, si k=número de muestras, se llama:",
                options: [
                    "Leave-One-Out Cross-Validation (LOOCV)",
                    "Stratified k-fold",
                    "Time series split",
                    "Train-test split"
                ],
                correct: 0,
                explanation: "LOOCV entrena el modelo n veces (donde n = número de muestras), cada vez dejando una muestra fuera. Da estimaciones muy precisas pero es computacionalmente costoso. Útil para datasets pequeños."
            },
            {
                question: "¿Qué es el bias en Machine Learning?",
                options: [
                    "Error por suposiciones simplificadoras del modelo",
                    "Ruido aleatorio en los datos",
                    "La diferencia entre train y test error",
                    "El término independiente en regresión"
                ],
                correct: 0,
                explanation: "Bias es el error introducido por aproximar un problema complejo del mundo real con un modelo más simple. Alto bias = underfitting (el modelo es demasiado simple para capturar patrones). Ej: usar regresión lineal para datos no-lineales."
            },
            {
                question: "¿Qué es la varianza en el contexto del bias-variance tradeoff?",
                options: [
                    "Sensibilidad del modelo a fluctuaciones en datos de entrenamiento",
                    "La dispersión de los datos",
                    "El error promedio del modelo",
                    "El número de parámetros"
                ],
                correct: 0,
                explanation: "Varianza mide cuánto cambian las predicciones del modelo si lo entrenamos con diferentes conjuntos de datos. Alta varianza = overfitting (el modelo es muy sensible a detalles específicos del training set). El objetivo es balancear bias y varianza."
            },
            {
                question: "Gradient Descent con momento (momentum) ayuda a:",
                options: [
                    "Acelerar la convergencia y evitar mínimos locales",
                    "Aumentar el learning rate automáticamente",
                    "Reducir el número de épocas",
                    "Eliminar la necesidad de regularización"
                ],
                correct: 0,
                explanation: "Momentum acumula una fracción del gradiente anterior (típicamente 0.9) al gradiente actual, como una bola rodando cuesta abajo. Esto ayuda a: 1) acelerar en direcciones consistentes, 2) amortiguar oscilaciones, 3) escapar de mínimos locales poco profundos."
            },
            {
                question: "¿Qué optimizador adapta el learning rate para cada parámetro?",
                options: [
                    "Adam (Adaptive Moment Estimation)",
                    "SGD básico",
                    "Batch Gradient Descent",
                    "Ninguno"
                ],
                correct: 0,
                explanation: "Adam combina las ventajas de AdaGrad (learning rates adaptativos) y RMSprop (decay de gradientes). Mantiene promedios móviles exponenciales de gradientes y sus cuadrados, adaptando el learning rate para cada parámetro. Es muy popular por su robustez."
            },
            {
                question: "En árboles de decisión, ¿qué es la poda (pruning)?",
                options: [
                    "Eliminar ramas para reducir overfitting",
                    "Añadir más niveles al árbol",
                    "Normalizar las características",
                    "Balancear las clases"
                ],
                correct: 0,
                explanation: "La poda elimina ramas que aportan poca información o que causan overfitting. Pre-poda (early stopping): parar el crecimiento antes. Post-poda: construir árbol completo y luego eliminar ramas. Usa métricas como validación cruzada para decidir qué podar."
            },
            {
                question: "¿Qué mide el índice Gini en árboles de decisión?",
                options: [
                    "La impureza o desorden de un nodo",
                    "La profundidad del árbol",
                    "El accuracy del modelo",
                    "El número de hojas"
                ],
                correct: 0,
                explanation: "Gini Impurity mide la probabilidad de clasificar incorrectamente un elemento aleatorio. Gini = 1 - Σ(pi²), donde pi es la proporción de clase i. Gini=0 = nodo puro, Gini=0.5 = máxima impureza (binario). Se usa como criterio alternativo a entropía."
            },
            {
                question: "Gradient Boosting construye modelos:",
                options: [
                    "Secuencialmente, cada uno corrigiendo errores del anterior",
                    "En paralelo de forma independiente",
                    "Usando solo el primer modelo",
                    "Sin usar árboles de decisión"
                ],
                correct: 0,
                explanation: "Gradient Boosting (ej: XGBoost, LightGBM) entrena modelos secuencialmente, donde cada nuevo modelo se enfoca en los errores (residuos) del ensemble anterior. Usa gradient descent en el espacio de funciones para minimizar una función de pérdida."
            },
            {
                question: "En una Red Neuronal Convolucional (CNN), las capas convolucionales extraen:",
                options: [
                    "Características locales espaciales (bordes, texturas, patrones)",
                    "Características globales únicamente",
                    "Solo colores de la imagen",
                    "Texto de imágenes"
                ],
                correct: 0,
                explanation: "Las capas convolucionales aplican filtros/kernels que se deslizan sobre la imagen detectando patrones locales. Capas tempranas detectan características simples (bordes, colores), capas profundas combinan estas en patrones complejos (formas, objetos). El peso compartido reduce parámetros."
            },
            {
                question: "Pooling (ej: Max Pooling) en CNNs sirve para:",
                options: [
                    "Reducir dimensionalidad y lograr invarianza a pequeñas traslaciones",
                    "Aumentar el número de parámetros",
                    "Clasificar la imagen",
                    "Normalizar valores de píxeles"
                ],
                correct: 0,
                explanation: "Max Pooling toma el valor máximo en una ventana (ej: 2x2), reduciendo las dimensiones espaciales. Beneficios: 1) reduce parámetros y computación, 2) provee invarianza a pequeñas traslaciones, 3) ayuda a extraer características dominantes."
            },
            {
                question: "En redes neuronales, ¿qué es backpropagation?",
                options: [
                    "Algoritmo para calcular gradientes usando la regla de la cadena",
                    "Una técnica de regularización",
                    "Un tipo de arquitectura de red",
                    "Un método de inicialización de pesos"
                ],
                correct: 0,
                explanation: "Backpropagation (propagación hacia atrás) usa la regla de la cadena del cálculo para calcular eficientemente gradientes de la función de pérdida con respecto a cada peso, propagando el error desde la salida hasta la entrada. Es fundamental para entrenar redes neuronales."
            },
            {
                question: "¿Qué es early stopping?",
                options: [
                    "Detener entrenamiento cuando el error de validación deja de mejorar",
                    "Iniciar el entrenamiento antes",
                    "Usar menos épocas siempre",
                    "Eliminar características"
                ],
                correct: 0,
                explanation: "Early stopping monitorea una métrica en el conjunto de validación durante el entrenamiento. Si deja de mejorar por N épocas consecutivas (patience), detiene el entrenamiento. Previene overfitting sin necesidad de entrenar hasta convergencia completa."
            },
            {
                question: "La matriz de confusión multiclase tiene dimensiones:",
                options: [
                    "n_clases × n_clases",
                    "Siempre 2×2",
                    "n_muestras × n_clases",
                    "n_características × n_clases"
                ],
                correct: 0,
                explanation: "Para k clases, la matriz de confusión es k×k. El elemento (i,j) representa instancias de clase i predichas como clase j. La diagonal contiene predicciones correctas. Se calculan métricas macro/micro averaged de esta matriz."
            },
            {
                question: "¿Qué hace la técnica de Data Augmentation?",
                options: [
                    "Crea variaciones de los datos existentes (rotaciones, flips, etc.)",
                    "Elimina datos ruidosos",
                    "Reduce el número de características",
                    "Aumenta el learning rate"
                ],
                correct: 0,
                explanation: "Data Augmentation genera nuevas muestras aplicando transformaciones (rotaciones, traslaciones, zoom, flips, cambios de brillo) a datos existentes. Aumenta efectivamente el tamaño del dataset, mejora la generalización y reduce overfitting, especialmente en visión por computadora."
            },
            {
                question: "En clustering, el coeficiente de silueta mide:",
                options: [
                    "Qué tan bien están separados y cohesionados los clusters",
                    "El número óptimo de dimensiones",
                    "El error de clasificación",
                    "La profundidad del árbol"
                ],
                correct: 0,
                explanation: "El coeficiente de silueta para cada punto mide: (b-a)/max(a,b), donde a=distancia promedio intra-cluster, b=distancia promedio al cluster más cercano. Valores: 1=excelente, 0=clusters superpuestos, -1=mal asignado. Se promedia sobre todos los puntos."
            },
            {
                question: "PCA (Principal Component Analysis) se usa para:",
                options: [
                    "Reducir dimensionalidad preservando máxima varianza",
                    "Clasificar datos",
                    "Aumentar el número de características",
                    "Balancear clases"
                ],
                correct: 0,
                explanation: "PCA identifica las direcciones (componentes principales) de máxima varianza en los datos mediante eigendecomposición de la matriz de covarianza. Proyectar datos en los primeros k componentes reduce dimensiones preservando la mayor información posible, útil para visualización y reducción de ruido."
            },
            {
                question: "La curva ROC grafica:",
                options: [
                    "Tasa de Verdaderos Positivos vs Tasa de Falsos Positivos",
                    "Precision vs Recall",
                    "Error vs Épocas",
                    "Accuracy vs Tiempo"
                ],
                correct: 0,
                explanation: "La curva ROC (Receiver Operating Characteristic) grafica TPR (Recall) en eje Y vs FPR (TN/(TN+FP)) en eje X variando el umbral de clasificación. AUC (Area Under Curve) mide la calidad: AUC=1 perfecto, AUC=0.5 aleatorio. Útil para evaluar clasificadores binarios independientemente del umbral."
            },
            {
                question: "¿Qué es AUC-ROC?",
                options: [
                    "Área bajo la curva ROC, mide capacidad de discriminación",
                    "Un algoritmo de clustering",
                    "Una función de activación",
                    "Un tipo de regularización"
                ],
                correct: 0,
                explanation: "AUC-ROC (Area Under the ROC Curve) mide la probabilidad de que el modelo ordene un ejemplo positivo aleatorio más alto que uno negativo. AUC=1: clasificador perfecto, AUC=0.5: no mejor que azar, AUC<0.5: peor que azar (invierte predicciones)."
            },
            {
                question: "En ensemble learning, ¿qué es bagging?",
                options: [
                    "Entrenar múltiples modelos en subconjuntos aleatorios con reemplazo",
                    "Entrenar modelos secuencialmente",
                    "Usar un solo modelo muy complejo",
                    "Reducir el número de características"
                ],
                correct: 0,
                explanation: "Bagging (Bootstrap Aggregating) entrena múltiples modelos en diferentes muestras bootstrap (muestreo con reemplazo) del dataset original, luego combina predicciones por votación/promedio. Reduce varianza sin aumentar bias. Random Forest es un ejemplo famoso de bagging."
            },
            {
                question: "La maldición de la dimensionalidad se refiere a:",
                options: [
                    "Problemas que surgen al trabajar con espacios de alta dimensión",
                    "Tener demasiados datos",
                    "Modelos muy simples",
                    "Pocos hiperparámetros"
                ],
                correct: 0,
                explanation: "En alta dimensión: 1) puntos se vuelven equidistantes (distancias pierden significado), 2) datos se vuelven sparse, 3) se necesitan exponencialmente más datos, 4) muchos algoritmos se vuelven ineficientes. Soluciones: reducción de dimensionalidad (PCA, selección de características)."
            },
            {
                question: "Transfer Learning consiste en:",
                options: [
                    "Usar un modelo pre-entrenado y adaptarlo a una nueva tarea",
                    "Transferir datos entre datasets",
                    "Cambiar el algoritmo durante entrenamiento",
                    "Convertir regresión a clasificación"
                ],
                correct: 0,
                explanation: "Transfer Learning aprovecha conocimiento aprendido de una tarea/dominio (ej: ImageNet) para otra relacionada. Típicamente se usa un modelo pre-entrenado como extractor de características o se fine-tunea. Muy efectivo cuando tienes pocos datos en la tarea objetivo."
            },
            {
                question: "¿Qué es feature engineering?",
                options: [
                    "Crear, transformar y seleccionar características para mejorar el modelo",
                    "Entrenar más rápido el modelo",
                    "Aumentar el learning rate",
                    "Reducir el número de clases"
                ],
                correct: 0,
                explanation: "Feature engineering es el arte de crear características informativas a partir de datos crudos: combinaciones, transformaciones (log, sqrt), binning, encoding categórico, extracción de fechas, agregaciones, etc. A menudo es más importante que el algoritmo elegido."
            },
            {
                question: "One-Hot Encoding se usa para:",
                options: [
                    "Convertir variables categóricas en vectores binarios",
                    "Normalizar datos numéricos",
                    "Reducir dimensiones",
                    "Inicializar pesos"
                ],
                correct: 0,
                explanation: "One-Hot Encoding convierte cada categoría en una columna binaria. Ej: Color={Rojo,Verde,Azul} → [1,0,0], [0,1,0], [0,0,1]. Necesario para algoritmos que requieren entrada numérica. Cuidado: puede crear muchas dimensiones con categorías numerosas (usa target encoding o embeddings)."
            },
            {
                question: "En K-NN (K-Nearest Neighbors), aumentar K generalmente:",
                options: [
                    "Reduce varianza pero aumenta bias",
                    "Aumenta varianza y reduce bias",
                    "No afecta el modelo",
                    "Solo afecta el tiempo de entrenamiento"
                ],
                correct: 0,
                explanation: "K-NN con K grande: fronteras de decisión más suaves (menos varianza, más bias, menos overfitting). K pequeño: fronteras complejas (más varianza, menos bias, más overfitting). K=1 memoriza datos. K=N siempre predice la clase mayoritaria. Óptimo: K moderado, impar para evitar empates."
            },
            {
                question: "¿Qué es un autoencoder?",
                options: [
                    "Red neuronal que aprende a comprimir y reconstruir datos",
                    "Un algoritmo de clustering",
                    "Una técnica de regularización",
                    "Un optimizador"
                ],
                correct: 0,
                explanation: "Un autoencoder tiene arquitectura encoder-decoder: comprime input a representación latente (bottleneck) y luego lo reconstruye. Se entrena minimizando error de reconstrucción. Usos: reducción de dimensionalidad, detección de anomalías, denoising, aprendizaje de características."
            },
            {
                question: "En series temporales, ¿qué es estacionariedad?",
                options: [
                    "Propiedades estadísticas (media, varianza) constantes en el tiempo",
                    "Datos sin valores faltantes",
                    "Frecuencia de muestreo constante",
                    "Ausencia de outliers"
                ],
                correct: 0,
                explanation: "Una serie es estacionaria si media, varianza y autocovarianza son constantes en el tiempo. La mayoría de modelos (ARIMA) asumen estacionariedad. Se logra mediante diferenciación, transformaciones (log), o detrending. Test Dickey-Fuller verifica estacionariedad."
            },
            {
                question: "La métrica Macro-Average en clasificación multiclase:",
                options: [
                    "Calcula métrica para cada clase y promedia sin pesar",
                    "Pondera por tamaño de clase",
                    "Solo considera la clase mayoritaria",
                    "Es igual al accuracy"
                ],
                correct: 0,
                explanation: "Macro-Average calcula la métrica (precision, recall, F1) independientemente para cada clase y promedia dándoles igual peso. Útil cuando todas las clases son igualmente importantes. Micro-Average agrega globalmente (pondera por frecuencia), útil con desbalance."
            },
            {
                question: "¿Qué es el learning rate en gradient descent?",
                options: [
                    "Tamaño del paso en dirección del gradiente",
                    "Velocidad de procesamiento de datos",
                    "Número de iteraciones",
                    "Porcentaje de datos de entrenamiento"
                ],
                correct: 0,
                explanation: "Learning rate (α o η) controla cuánto actualizamos los pesos: peso_nuevo = peso_viejo - α*gradiente. α muy alto: puede diverger/oscilar. α muy bajo: converge lentamente. Técnicas: learning rate schedules (decay), adaptive rates (Adam), warm-up."
            },
            {
                question: "¿Qué algoritmo usa 'voting' para clasificar?",
                options: [
                    "Random Forest y otros métodos ensemble",
                    "Regresión Logística",
                    "K-Means",
                    "PCA"
                ],
                correct: 0,
                explanation: "Ensemble methods combinan múltiples modelos base mediante voting: hard voting (mayoría de votos) para clasificación, soft voting (promedio de probabilidades), averaging para regresión. Random Forest, Voting Classifier son ejemplos que aprovechan la sabiduría de la multitud."
            },
            {
                question: "La regularización L1 y L2 se diferencian en que L1:",
                options: [
                    "Puede hacer coeficientes exactamente cero (sparse)",
                    "Siempre da coeficientes mayores",
                    "No reduce overfitting",
                    "Es más computacionalmente costosa"
                ],
                correct: 0,
                explanation: "L1 (Lasso) usa |β|: genera sparsity (coeficientes exactamente 0), bueno para selección de características. L2 (Ridge) usa β²: reduce magnitud pero rara vez hace 0, mejor con multicolinealidad. Elastic Net combina ambas: α*L1 + (1-α)*L2."
            },
            {
                question: "En neural networks, ¿qué es el vanishing gradient problem?",
                options: [
                    "Gradientes muy pequeños que dificultan aprendizaje en capas iniciales",
                    "Falta de datos de entrenamiento",
                    "Overfitting severo",
                    "Errores de implementación"
                ],
                correct: 0,
                explanation: "Con sigmoid/tanh, gradientes se multiplican en backprop y decaen exponencialmente en redes profundas. Soluciones: ReLU (no satura), Batch Normalization, arquitecturas residuales (ResNet), LSTM/GRU (para RNNs), inicialización cuidadosa (He, Xavier)."
            },
            {
                question: "¿Qué tipo de problema es detectar emails spam?",
                options: [
                    "Clasificación binaria supervisada",
                    "Regresión",
                    "Clustering no supervisado",
                    "Aprendizaje por refuerzo"
                ],
                correct: 0,
                explanation: "Detectar spam es clasificación binaria (spam/no spam) supervisada porque tenemos etiquetas. Algoritmos comunes: Naive Bayes (clásico para texto), Regresión Logística, SVM, Random Forest. Features: frecuencia de palabras (TF-IDF), metadatos del email."
            },
            {
                question: "Naive Bayes asume que las características son:",
                options: [
                    "Condicionalmente independientes dada la clase",
                    "Altamente correlacionadas",
                    "Distribuidas uniformemente",
                    "Categóricas siempre"
                ],
                correct: 0,
                explanation: "Naive Bayes aplica teorema de Bayes asumiendo independencia condicional: P(X|Y) = ∏P(xi|Y). Esta asunción 'naive' (ingenua) rara vez es cierta pero el algoritmo funciona sorprendentemente bien en práctica, especialmente en clasificación de texto (spam, sentimiento)."
            },
            {
                question: "En Deep Learning, ¿qué es fine-tuning?",
                options: [
                    "Reentrenar parcialmente un modelo pre-entrenado en nuevos datos",
                    "Aumentar el número de capas",
                    "Reducir el learning rate solamente",
                    "Eliminar neuronas"
                ],
                correct: 0,
                explanation: "Fine-tuning: 1) Tomar modelo pre-entrenado (ej: en ImageNet), 2) Congelar capas iniciales (características generales), 3) Reentrenar capas finales + nueva capa de clasificación en dataset específico con learning rate bajo. Aprovecha transfer learning efectivamente."
            },
            // REGRESIÓN LINEAL
            {
                question: "¿Cuál es el supuesto de homocedasticidad en regresión lineal?",
                options: [
                    "La varianza de los residuos es constante",
                    "Los residuos siguen una distribución normal",
                    "Las variables independientes no están correlacionadas",
                    "La relación es lineal"
                ],
                correct: 0,
                explanation: "Homocedasticidad significa que la varianza de los errores es constante para todos los valores de X. Si se viola (heterocedasticidad), los intervalos de confianza y tests de hipótesis no son confiables. Se detecta con gráficos de residuos vs predicciones o test de Breusch-Pagan."
            },
            {
                question: "¿Qué mide el coeficiente R² (R cuadrado)?",
                options: [
                    "Proporción de varianza explicada por el modelo",
                    "Error medio del modelo",
                    "Correlación entre variables",
                    "Número de outliers"
                ],
                correct: 0,
                explanation: "R² = 1 - (SSR/SST) mide qué porcentaje de la variabilidad de Y es explicada por el modelo. R²=1 perfecto, R²=0 no explica nada. CUIDADO: R² siempre aumenta al agregar variables, usa R² ajustado para comparar modelos con diferente número de predictores."
            },
            {
                question: "En regresión lineal múltiple, ¿qué es multicolinealidad?",
                options: [
                    "Alta correlación entre variables independientes",
                    "Relación no lineal entre X e Y",
                    "Presencia de outliers",
                    "Variables con diferentes escalas"
                ],
                correct: 0,
                explanation: "Multicolinealidad ocurre cuando predictores están altamente correlacionados, haciendo inestables los coeficientes (pequeños cambios en datos → grandes cambios en β). Detectar: VIF (Variance Inflation Factor) > 10. Soluciones: eliminar variables, PCA, regularización (Ridge)."
            },
            {
                question: "¿Qué supuesto viola si los residuos muestran un patrón en forma de embudo?",
                options: [
                    "Homocedasticidad (heterocedasticidad presente)",
                    "Normalidad",
                    "Independencia",
                    "Linealidad"
                ],
                correct: 0,
                explanation: "Un patrón de embudo en residuos vs predicciones indica heterocedasticidad: la varianza de errores aumenta/disminuye con las predicciones. Soluciones: transformaciones (log, sqrt), WLS (Weighted Least Squares), modelos robustos."
            },
            {
                question: "En regresión lineal, ¿cómo interpretas un coeficiente β₁ = 3.5?",
                options: [
                    "Por cada unidad de aumento en X₁, Y aumenta 3.5 (manteniendo otros constantes)",
                    "X₁ explica 3.5% de la varianza",
                    "El error del modelo es 3.5",
                    "La correlación con Y es 3.5"
                ],
                correct: 0,
                explanation: "Los coeficientes en regresión lineal se interpretan como el cambio en Y por cada unidad de cambio en Xi, manteniendo todas las demás variables constantes (ceteris paribus). La magnitud depende de las unidades de medición."
            },
            {
                question: "¿Cuándo usarías regresión polinomial en lugar de lineal simple?",
                options: [
                    "Cuando la relación entre X e Y es curvilínea",
                    "Cuando tienes muchas variables",
                    "Cuando hay valores faltantes",
                    "Cuando las clases están desbalanceadas"
                ],
                correct: 0,
                explanation: "Regresión polinomial (Y = β₀ + β₁X + β₂X² + ... + βₙXⁿ) modela relaciones no lineales. Por ejemplo: rendimiento vs esfuerzo (curva U invertida). Cuidado: polinomios de alto grado pueden causar overfitting."
            },
            {
                question: "¿Qué detecta un gráfico Q-Q (Quantile-Quantile) de residuos?",
                options: [
                    "Si los residuos siguen distribución normal",
                    "Heterocedasticidad",
                    "Multicolinealidad",
                    "Outliers en variables independientes"
                ],
                correct: 0,
                explanation: "El gráfico Q-Q compara los cuantiles de los residuos con los de una distribución normal teórica. Si los puntos se alinean en la diagonal, los residuos son aproximadamente normales. Desviaciones indican violación del supuesto de normalidad."
            },
            {
                question: "El error estándar de los coeficientes en regresión mide:",
                options: [
                    "La incertidumbre/variabilidad en la estimación del coeficiente",
                    "El error de predicción del modelo",
                    "La correlación entre variables",
                    "El número de outliers"
                ],
                correct: 0,
                explanation: "El error estándar (SE) de β indica qué tan precisa es nuestra estimación. Se usa para construir intervalos de confianza (β ± t*SE) y realizar tests de hipótesis (t = β/SE). Menor SE = estimación más precisa."
            },
            {
                question: "¿Qué indica un p-valor < 0.05 para un coeficiente en regresión?",
                options: [
                    "La variable es estadísticamente significativa al 95% de confianza",
                    "El modelo explica 5% de la varianza",
                    "Hay un error del 5% en los datos",
                    "El R² es menor a 0.05"
                ],
                correct: 0,
                explanation: "p-valor < 0.05 indica que rechazamos la hipótesis nula (β=0) con 95% de confianza, sugiriendo que la variable tiene un efecto estadísticamente significativo en Y. PERO significancia estadística ≠ significancia práctica. Considera también magnitud del efecto."
            },
            // REGRESIÓN LOGÍSTICA
            {
                question: "En regresión logística, ¿qué representa exp(β₁)?",
                options: [
                    "El odds ratio: cuánto cambian las odds al aumentar X₁ una unidad",
                    "La probabilidad de la clase positiva",
                    "El error del modelo",
                    "La correlación con Y"
                ],
                correct: 0,
                explanation: "exp(β) es el odds ratio (OR). Si β₁=0.5, OR=e^0.5≈1.65: las odds de éxito aumentan 65% por cada unidad de X₁. OR>1 efecto positivo, OR<1 negativo, OR=1 sin efecto. Muy útil para interpretación en medicina/ciencias sociales."
            },
            {
                question: "La función de pérdida en regresión logística es:",
                options: [
                    "Log-loss (entropía cruzada binaria)",
                    "Error cuadrático medio (MSE)",
                    "Error absoluto medio (MAE)",
                    "Hinge loss"
                ],
                correct: 0,
                explanation: "Regresión logística usa log-loss: -[y*log(p) + (1-y)*log(1-p)]. Penaliza fuertemente predicciones confiadas e incorrectas. No usa MSE porque crearía superficie no convexa con múltiples mínimos locales, dificultando optimización."
            },
            {
                question: "¿Cuál es la principal diferencia entre regresión lineal y logística?",
                options: [
                    "Lineal predice valores continuos, logística predice probabilidades/clases",
                    "Logística es más rápida de entrenar",
                    "Lineal requiere más datos",
                    "Son el mismo algoritmo"
                ],
                correct: 0,
                explanation: "Regresión lineal: Y continua, predice valores (ej: precio casas). Regresión logística: clasificación, predice P(Y=1) mediante función sigmoide, luego usa umbral para asignar clase. Aunque comparten 'regresión' en el nombre, resuelven problemas diferentes."
            },
            {
                question: "Aplicación real de regresión logística:",
                options: [
                    "Predecir si un cliente cancelará su suscripción (churn)",
                    "Predecir el precio exacto de una casa",
                    "Agrupar clientes similares",
                    "Reducir dimensiones de imágenes"
                ],
                correct: 0,
                explanation: "Regresión logística es ideal para clasificación binaria: churn prediction, aprobación de créditos, diagnóstico médico (enfermo/sano), email spam, fraude en tarjetas, click-through rate. Es interpretable (puedes explicar el impacto de cada variable) y eficiente."
            },
            {
                question: "¿Por qué normalizar características antes de regresión logística con regularización?",
                options: [
                    "Para que la penalización afecte igualmente a todos los coeficientes",
                    "Para que el modelo converja",
                    "No es necesario normalizar",
                    "Para mejorar la precisión únicamente"
                ],
                correct: 0,
                explanation: "Sin normalización, variables con rangos grandes dominan la penalización L1/L2, sesgando qué coeficientes se reducen. Normalizar (StandardScaler, MinMaxScaler) pone todas las variables en la misma escala, haciendo que la regularización trate a todas equitativamente."
            },
            {
                question: "En regresión logística multiclase, ¿qué estrategia usa One-vs-Rest (OvR)?",
                options: [
                    "Entrena un clasificador binario para cada clase vs todas las demás",
                    "Agrupa todas las clases en una sola",
                    "Usa solo dos clases siempre",
                    "Elimina clases minoritarias"
                ],
                correct: 0,
                explanation: "One-vs-Rest (también llamado One-vs-All): para K clases, entrena K clasificadores binarios. Cada uno distingue una clase de todas las demás. Predicción: clase con mayor confianza/probabilidad. Alternativa: One-vs-One (K*(K-1)/2 clasificadores)."
            },
            {
                question: "¿Qué significa que un modelo de regresión logística está 'calibrado'?",
                options: [
                    "Sus probabilidades predichas reflejan la verdadera probabilidad de ocurrencia",
                    "Tiene alta precisión",
                    "No tiene overfitting",
                    "Usa regularización"
                ],
                correct: 0,
                explanation: "Un modelo calibrado: si predice P=0.7 para 100 casos, aproximadamente 70 son positivos. Se evalúa con calibration plots o Brier score. Importante en medicina/finanzas donde las probabilidades exactas importan. Platt scaling o isotonic regression pueden calibrar modelos."
            },
            // K-NEAREST NEIGHBORS (KNN)
            {
                question: "En K-NN, ¿por qué es crítico normalizar las características?",
                options: [
                    "Evita que variables con rangos grandes dominen el cálculo de distancia",
                    "Acelera el entrenamiento",
                    "Reduce el número de vecinos necesarios",
                    "Elimina la necesidad de elegir K"
                ],
                correct: 0,
                explanation: "K-NN usa distancia (típicamente euclidiana). Sin normalización, una variable en escala 0-1000 dominará sobre otra en 0-1. Ejemplo: edad (0-100) vs ingreso ($0-$1M) → ingreso domina. Solución: StandardScaler o MinMaxScaler antes de KNN."
            },
            {
                question: "¿Cuál es una DESVENTAJA principal de K-NN?",
                options: [
                    "Lento en predicción con datasets grandes (no lazy learning en training)",
                    "No puede manejar datos categóricos",
                    "Solo funciona para clasificación binaria",
                    "Siempre hace overfitting"
                ],
                correct: 0,
                explanation: "K-NN es 'lazy learner': no hay entrenamiento, pero predicción es O(n*d) donde n=muestras, d=dimensiones. Debe calcular distancia a TODOS los puntos. Soluciones: algoritmos rápidos (Ball Tree, KD-Tree), reducción de dimensiones, sampling del dataset."
            },
            {
                question: "¿Qué métrica de distancia es más robusta a outliers en K-NN?",
                options: [
                    "Manhattan (L1)",
                    "Euclidiana (L2)",
                    "Distancia de Chebyshev",
                    "Todas son igualmente sensibles"
                ],
                correct: 0,
                explanation: "Manhattan (suma de diferencias absolutas) es más robusta que Euclidiana (que eleva al cuadrado las diferencias, amplificando outliers). Otras opciones: Minkowski (generalización), Hamming (categóricas), Cosine (text/documentos). Elegir según tipo de datos y problema."
            },
            {
                question: "En K-NN para regresión, la predicción es:",
                options: [
                    "El promedio de los valores de los K vecinos más cercanos",
                    "El valor del vecino más cercano únicamente",
                    "La mediana de todos los datos",
                    "Una combinación lineal de todas las características"
                ],
                correct: 0,
                explanation: "K-NN regresión: predicción = promedio (o mediana) de los K vecinos. Variante: weighted K-NN (vecinos más cercanos tienen más peso, ej: 1/distancia). K-NN clasificación usa votación mayoritaria (o ponderada por distancia)."
            },
            {
                question: "¿Cómo afecta la 'maldición de la dimensionalidad' a K-NN?",
                options: [
                    "En alta dimensión, todos los puntos están casi equidistantes",
                    "Requiere más vecinos K",
                    "Mejora la precisión automáticamente",
                    "No afecta a K-NN"
                ],
                correct: 0,
                explanation: "En espacios de alta dimensión, las distancias se vuelven similares, haciendo que 'vecinos cercanos' no sean realmente cercanos en sentido intuitivo. Solución: reducción de dimensionalidad (PCA, feature selection), usar algoritmos menos sensibles a dimensión."
            },
            {
                question: "Aplicación real de K-NN:",
                options: [
                    "Sistemas de recomendación (encontrar usuarios/productos similares)",
                    "Predicción de series temporales largas",
                    "Generación de texto",
                    "Compresión de imágenes"
                ],
                correct: 0,
                explanation: "K-NN es excelente para: sistemas de recomendación (Netflix: usuarios similares), reconocimiento de patrones, clasificación de imágenes (simple baseline), detección de anomalías (puntos sin vecinos cercanos), imputación de datos faltantes (usar vecinos)."
            },
            {
                question: "¿Por qué K debe ser impar en K-NN para clasificación binaria?",
                options: [
                    "Para evitar empates en la votación",
                    "Porque el algoritmo solo acepta impares",
                    "Para mejorar la precisión",
                    "No hay razón, puede ser par"
                ],
                correct: 0,
                explanation: "K impar evita empates en votación binaria (ej: K=4 → 2 vs 2). Sin embargo, en multiclase los empates pueden ocurrir igual. Solución a empates: usar distancias ponderadas, reducir a K-1, aleatorio. En práctica, elegir K por cross-validation."
            },
            {
                question: "¿Cuál es el 'entrenamiento' en K-NN?",
                options: [
                    "Solo almacenar los datos (no hay entrenamiento real)",
                    "Calcular centroides como K-Means",
                    "Ajustar pesos mediante gradient descent",
                    "Construir un árbol de decisión"
                ],
                correct: 0,
                explanation: "K-NN es 'instance-based' o 'memory-based': el 'entrenamiento' es simplemente guardar los datos. Todo el trabajo ocurre en predicción (calcular distancias). Ventaja: adapta instantáneamente a nuevos datos. Desventaja: requiere almacenar todo el dataset."
            },
            // APLICACIONES REALES
            {
                question: "¿Qué algoritmo usarías para segmentar clientes en grupos de comportamiento similar?",
                options: [
                    "K-Means o clustering jerárquico",
                    "Regresión lineal",
                    "Regresión logística",
                    "Decision Trees para clasificación"
                ],
                correct: 0,
                explanation: "Segmentación de clientes es clustering no supervisado: agrupa clientes por características similares (RFM: recency, frequency, monetary) sin etiquetas predefinidas. K-Means es popular por eficiencia. Luego analiza cada segmento y crea estrategias de marketing personalizadas."
            },
            {
                question: "Para detectar transacciones fraudulentas con tarjeta de crédito:",
                options: [
                    "Clasificación con clases desbalanceadas (muy pocos fraudes)",
                    "Regresión para predecir monto",
                    "Clustering sin supervisión",
                    "Reducción de dimensionalidad únicamente"
                ],
                correct: 0,
                explanation: "Detección de fraude: clasificación binaria MUY desbalanceada (<1% fraudes). Técnicas: 1) SMOTE/undersampling, 2) usar F1/Recall en lugar de Accuracy, 3) Isolation Forest/autoencoders para anomalías, 4) ensemble methods (XGBoost), 5) cost-sensitive learning (penalizar más FN)."
            },
            {
                question: "Para un sistema de reconocimiento facial, ¿qué arquitectura es más apropiada?",
                options: [
                    "Redes Neuronales Convolucionales (CNN)",
                    "Regresión logística simple",
                    "K-Means clustering",
                    "Árboles de decisión"
                ],
                correct: 0,
                explanation: "Reconocimiento facial usa CNNs profundas (FaceNet, DeepFace, VGGFace): extraen características faciales (embeddings) invariantes a iluminación, pose, expresión. Típicamente: CNN pre-entrenada + triplet loss o clasificación multiclase. Transfer learning común con modelos pre-entrenados."
            },
            {
                question: "Para predecir la demanda de productos en retail (forecasting):",
                options: [
                    "Modelos de series temporales (ARIMA, Prophet, LSTM)",
                    "K-NN sin considerar el tiempo",
                    "Clustering de productos",
                    "PCA para reducir productos"
                ],
                correct: 0,
                explanation: "Forecasting de demanda requiere modelos de series temporales que capturen: tendencias, estacionalidad, componentes cíclicos. Opciones: ARIMA (clásico), Prophet (Facebook, maneja estacionalidad/holidays), LSTM/GRU (deep learning para patrones complejos), XGBoost con features temporales."
            },
            {
                question: "En diagnóstico médico automatizado, ¿qué métrica priorizar?",
                options: [
                    "Recall (Sensibilidad) para no perder casos positivos",
                    "Precision únicamente",
                    "Accuracy total",
                    "Velocidad de predicción"
                ],
                correct: 0,
                explanation: "En medicina, un Falso Negativo (no detectar enfermedad) es típicamente más costoso que Falso Positivo (más pruebas). Por ello, priorizar Recall alto asegura detectar la mayoría de casos. Luego, segunda etapa con más pruebas puede filtrar FP. Balance con Precision vía F1 o F2 (pondera más Recall)."
            },
            {
                question: "Para análisis de sentimiento en redes sociales:",
                options: [
                    "Procesamiento de Lenguaje Natural (BERT, transformers, o Naive Bayes)",
                    "K-Means en el texto directo",
                    "Regresión lineal en palabras",
                    "DBSCAN clustering"
                ],
                correct: 0,
                explanation: "Análisis de sentimiento (positivo/negativo/neutral): 1) Clásico: TF-IDF + Naive Bayes/SVM, 2) Moderno: BERT, RoBERTa (transformers pre-entrenados), 3) Aspectos: detectar sobre qué tema es el sentimiento. Desafíos: sarcasmo, contexto, emojis, slang."
            },
            {
                question: "Para un sistema de filtrado de spam de email:",
                options: [
                    "Naive Bayes (clásico) o modelos de texto modernos",
                    "Regresión lineal en longitud del email",
                    "K-Means para agrupar emails",
                    "PCA en palabras"
                ],
                correct: 0,
                explanation: "Filtros de spam: Naive Bayes Multinomial es clásico y efectivo (asume independencia de palabras dado spam/no-spam). Features: frecuencia de palabras, TF-IDF, metadatos (remitente, hora). Modernos: BERT, ensemble methods. Desafío: adversarial attacks (spammers evaden filtros)."
            },
            {
                question: "En motores de búsqueda, para rankear resultados por relevancia:",
                options: [
                    "Learning to Rank (LambdaMART, RankNet) con múltiples features",
                    "Ordenar alfabéticamente",
                    "K-Means clustering",
                    "Regresión lineal simple"
                ],
                correct: 0,
                explanation: "Learning to Rank usa ML para ordenar resultados: combina señales (TF-IDF, PageRank, clickthrough rate, frescura, ubicación). Enfoques: pointwise (score individual), pairwise (comparaciones), listwise (optimiza lista completa). Métricas: NDCG, MAP. Ejemplos: Google, Bing."
            },
            {
                question: "Para detección de objetos en tiempo real (ej: autos autónomos):",
                options: [
                    "YOLO, SSD, o Faster R-CNN (CNNs especializadas)",
                    "Regresión logística en píxeles",
                    "K-Means en colores",
                    "Decision Trees simples"
                ],
                correct: 0,
                explanation: "Detección de objetos en tiempo real: YOLO (You Only Look Once) divide imagen en grid y predice bounding boxes + clases simultáneamente. Alternativas: SSD, Faster R-CNN (más preciso, más lento). Requiere CNNs profundas, GPUs, y entrenamiento con datasets anotados (COCO, ImageNet)."
            },
            {
                question: "Para predecir el precio de una vivienda:",
                options: [
                    "Regresión (lineal, Ridge, Lasso, Random Forest, XGBoost)",
                    "Clasificación en categorías de precio",
                    "Clustering de casas similares",
                    "K-NN sin features numéricas"
                ],
                correct: 0,
                explanation: "Predicción de precios es regresión: predice valor continuo. Features: m², ubicación, # habitaciones, año construcción, amenidades. Modelos: regresión lineal (baseline interpretable), Ridge/Lasso (regularización), Random Forest/XGBoost (capturan no-linealidades), ensembles. Métrica: RMSE, MAE."
            },
            {
                question: "En sistemas de traducción automática modernos:",
                options: [
                    "Transformers (attention mechanisms) como Google Translate",
                    "Regresión logística palabra por palabra",
                    "K-Means en vocabulario",
                    "Decision Trees para sintaxis"
                ],
                correct: 0,
                explanation: "Traducción automática moderna usa Transformers (BERT, GPT, T5): arquitectura encoder-decoder con attention mechanisms que captura contexto largo y relaciones entre palabras. Supera RNNs/LSTMs previas. Se entrena en corpus paralelos masivos. Google Translate, DeepL usan variantes de transformers."
            },
            {
                question: "Para optimizar rutas de entrega (ej: logística):",
                options: [
                    "Algoritmos de optimización (genéticos, simulated annealing) + ML para predecir tiempos",
                    "Solo K-Means para agrupar",
                    "Regresión lineal únicamente",
                    "Clustering jerárquico"
                ],
                correct: 0,
                explanation: "Optimización de rutas (Traveling Salesman Problem): algoritmos heurísticos (genéticos, ant colony, simulated annealing) + ML para predecir: tiempos de viaje (considerando tráfico), demanda, ventanas de tiempo. Reinforcement Learning también se usa (DeepMind para Google Maps)."
            },
            {
                question: "En un chatbot conversacional inteligente:",
                options: [
                    "LLMs (GPT, BERT) + NLU para entender intención y contexto",
                    "Reglas if-else únicamente",
                    "K-Means para agrupar preguntas",
                    "Regresión para predecir respuestas"
                ],
                correct: 0,
                explanation: "Chatbots modernos: 1) NLU (Natural Language Understanding) para detectar intención y entidades, 2) Gestión de diálogo (context tracking), 3) Generación de respuesta (templates o LLMs como GPT). Frameworks: Rasa, Dialogflow, Azure Bot. Desafíos: ambigüedad, contexto multi-turno."
            },
            {
                question: "Para predecir churn (abandono) de clientes en telecom:",
                options: [
                    "Clasificación binaria con features de uso, satisfacción, demografía",
                    "Regresión del tiempo hasta abandono",
                    "Clustering sin etiquetas",
                    "Análisis de correlación únicamente"
                ],
                correct: 0,
                explanation: "Churn prediction: clasificación binaria (se va / se queda). Features: uso de servicios, quejas, cambios de plan, competencia, satisfacción (NPS), demografía. Modelos: logística (interpretable), Random Forest, XGBoost. Acción: campaña de retención a clientes de alto riesgo. Métrica: Recall (detectar churners)."
            },
            {
                question: "En procesamiento de imágenes médicas (radiografías, MRIs):",
                options: [
                    "CNNs profundas (ResNet, U-Net para segmentación)",
                    "Regresión lineal en píxeles",
                    "K-Means para clasificar imágenes",
                    "Árboles de decisión en intensidades"
                ],
                correct: 0,
                explanation: "Imágenes médicas: CNNs para clasificación (cáncer/no cáncer), segmentación (U-Net identifica tumores), detección. Desafíos: pocos datos etiquetados (transfer learning), alta dimensión, interpretabilidad crítica (saliency maps, GradCAM). Regulación estricta (FDA approval)."
            },
            {
                question: "Para predecir fallas en maquinaria industrial (mantenimiento predictivo):",
                options: [
                    "Series temporales + clasificación en sensores IoT",
                    "Clustering de máquinas similares",
                    "Regresión simple sin considerar tiempo",
                    "PCA para visualizar máquinas"
                ],
                correct: 0,
                explanation: "Mantenimiento predictivo: sensores IoT (vibración, temperatura, presión) → modelos de series temporales detectan anomalías o predicen RUL (Remaining Useful Life). Técnicas: LSTM para secuencias, Isolation Forest para anomalías, clasificación (va a fallar sí/no). Ahorra costos vs mantenimiento preventivo programado."
            }
        ];

        // Actualizar total de preguntas en pantalla de inicio
        document.getElementById('totalQuestions').textContent = questionBank.length;

        let currentQuiz = [];
        let currentQuestionIndex = 0;
        let score = 0;
        let answered = false;

        function shuffleArray(array) {
            const newArray = [...array];
            for (let i = newArray.length - 1; i > 0; i--) {
                const j = Math.floor(Math.random() * (i + 1));
                [newArray[i], newArray[j]] = [newArray[j], newArray[i]];
            }
            return newArray;
        }

        function startQuiz() {
            currentQuiz = shuffleArray(questionBank); // Usa TODAS las preguntas
            currentQuestionIndex = 0;
            score = 0;
            answered = false;

            document.getElementById('startScreen').style.display = 'none';
            document.getElementById('quizScreen').style.display = 'block';
            document.getElementById('resultScreen').style.display = 'none';
            document.getElementById('totalQuestionsQuiz').textContent = currentQuiz.length;

            loadQuestion();
        }

        function loadQuestion() {
            answered = false;
            const question = currentQuiz[currentQuestionIndex];
            
            document.getElementById('currentQuestion').textContent = currentQuestionIndex + 1;
            document.getElementById('questionText').textContent = question.question;
            document.getElementById('explanationContainer').style.display = 'none';
            document.getElementById('nextBtn').style.display = 'none';
            
            const optionsContainer = document.getElementById('optionsContainer');
            optionsContainer.innerHTML = '';
            
            question.options.forEach((option, index) => {
                const btn = document.createElement('button');
                btn.className = 'btn btn-outline-secondary option-btn w-100 animate__animated animate__fadeInLeft';
                btn.style.animationDelay = `${index * 0.1}s`;
                btn.innerHTML = `<strong>${String.fromCharCode(65 + index)}.</strong> ${option}`;
                btn.onclick = () => checkAnswer(index);
                optionsContainer.appendChild(btn);
            });

            updateProgress();
        }

        function checkAnswer(selectedIndex) {
            if (answered) return;
            answered = true;

            const question = currentQuiz[currentQuestionIndex];
            const buttons = document.querySelectorAll('.option-btn');
            
            buttons.forEach((btn, index) => {
                btn.disabled = true;
                if (index === question.correct) {
                    btn.classList.add('correct');
                    btn.innerHTML += ' <i class="fas fa-check-circle text-success"></i>';
                }
                if (index === selectedIndex && selectedIndex !== question.correct) {
                    btn.classList.add('incorrect');
                    btn.innerHTML += ' <i class="fas fa-times-circle text-danger"></i>';
                }
            });

            if (selectedIndex === question.correct) {
                score++;
                document.getElementById('score').textContent = score;
                swal({
                    title: "¡Correcto!",
                    text: "Excelente trabajo",
                    icon: "success",
                    button: "Continuar",
                    timer: 2000
                });
            } else {
                swal({
                    title: "Incorrecto",
                    text: "Revisa la explicación abajo",
                    icon: "error",
                    button: "Entendido"
                });
            }

            showExplanation(question, selectedIndex);
            document.getElementById('nextBtn').style.display = 'block';
        }

        function showExplanation(question, selectedIndex) {
            const container = document.getElementById('explanationContainer');
            const isCorrect = selectedIndex === question.correct;
            
            container.innerHTML = `
                <div class="explanation-box animate__animated animate__fadeIn">
                    <h5 class="mb-3">
                        <i class="fas fa-lightbulb text-warning"></i> 
                        ${isCorrect ? 'Explicación' : '¿Por qué está mal?'}
                    </h5>
                    ${!isCorrect ? `<p><strong>Respuesta correcta:</strong> ${question.options[question.correct]}</p>` : ''}
                    <p>${question.explanation}</p>
                </div>
            `;
            container.style.display = 'block';
        }

        function nextQuestion() {
            currentQuestionIndex++;
            
            if (currentQuestionIndex < currentQuiz.length) {
                document.getElementById('quizScreen').classList.remove('animate__fadeIn');
                document.getElementById('quizScreen').classList.add('animate__fadeOut');
                
                setTimeout(() => {
                    document.getElementById('quizScreen').classList.remove('animate__fadeOut');
                    document.getElementById('quizScreen').classList.add('animate__fadeIn');
                    loadQuestion();
                }, 300);
            } else {
                showResults();
            }
        }

        function updateProgress() {
            const progress = ((currentQuestionIndex + 1) / currentQuiz.length) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        }

        function showResults() {
            document.getElementById('quizScreen').style.display = 'none';
            document.getElementById('resultScreen').style.display = 'block';
            
            const percentage = (score / currentQuiz.length) * 100;
            document.getElementById('finalScore').textContent = `${score} / ${currentQuiz.length}`;
            
            let message = '';
            let emoji = '';
            
            if (percentage >= 90) {
                message = '¡Excelente! Dominas muy bien Machine Learning';
                emoji = '🏆';
            } else if (percentage >= 70) {
                message = '¡Muy bien! Tienes buenos conocimientos';
                emoji = '🎯';
            } else if (percentage >= 50) {
                message = 'Buen intento. Sigue practicando';
                emoji = '📚';
            } else {
                message = 'Necesitas reforzar tus conocimientos';
                emoji = '💪';
            }
            
            document.getElementById('performance').innerHTML = `
                <h3 class="mb-3">${emoji} ${percentage.toFixed(1)}%</h3>
                <p class="lead">${message}</p>
            `;

            swal({
                title: "¡Quiz Completado!",
                text: `Obtuviste ${score} de ${currentQuiz.length} respuestas correctas (${percentage.toFixed(1)}%)`,
                icon: percentage >= 70 ? "success" : "info",
                button: "Ver Resultados"
            });
        }
    </script>
</body>
</html>